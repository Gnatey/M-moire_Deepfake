import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from streamlit_extras.metric_cards import style_metric_cards
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# --- Configuration de la page ---
st.set_page_config(
    page_title="Dashboard DeepFakes",
    page_icon="üñºÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Style CSS personnalis√© ---
def local_css(file_name):
    try:
        with open(file_name) as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except:
        pass

local_css("style.css")

# --- Constantes pour les noms de colonnes ---
COL_IMPACT = "Selon vous, quel est l'impact global des Deep Fakes sur la soci√©t√© ?"
COL_KNOWLEDGE = "Comment √©valueriez vous votre niveau de connaissance des Deep Fakes ?"
COL_EXPOSURE = "Avez-vous d√©j√† vu un Deep Fake sur les r√©seaux sociaux ?"
COL_AWARENESS = "Avez-vous d√©j√† entendu parler des Deep Fakes ?"
COL_VERIFICATION = "√Ä quelle fr√©quence v√©rifiez-vous l'authenticit√© d'une information avant de la partager ?"
COL_METHODS = "Quelles sont vos m√©thodes de v√©rification des informations en ligne ? (Plusieurs choix possibles)"
COL_PLATFORMS = "_Sur quelles plateformes avez-vous principalement vu des Deep Fakes ? (Plusieurs choix possibles)"
COL_TRUST = "Faites-vous confiance aux informations que vous trouvez sur les r√©seaux sociaux ?"
COL_TRUST_CHANGE = "Depuis que vous avez entendu parler des Deep Fakes, votre confiance dans les m√©dias sociaux a-t-elle chang√© ?"
COL_SHARING = "Avez-vous r√©duit la fr√©quence de partage d'informations sur les r√©seaux sociaux √† cause de la m√©fiance li√©e aux Deep Fakes"

# --- Chargement des donn√©es ---
@st.cache_data
def load_data():
    url = "https://raw.githubusercontent.com/Gnatey/M-moire_Deepfake/main/DeepFakes.csv"
    df = pd.read_csv(url, delimiter=";", encoding="utf-8")
    
    # Print original columns for debugging
    print("Original columns:", df.columns.tolist())
    
    # Nettoyage et pr√©paration des donn√©es
    df = df.rename(columns={
        "Quel est votre tranche d'√¢ge ?": "Age",
        "Vous √™tes ...?": "Genre",
        "Quel est votre niveau d'√©ducation actuel ?": "Education",
        "Quel est votre principal r√©seau social utilis√© au quotidien ?": "Reseau_Social"
    })
    
    # Standardisation des valeurs
    df['Reseau_Social'] = df['Reseau_Social'].replace({
        "X anciennement Twitter": "Twitter",
        "Aucun": "Pas de r√©seau"
    })
    
    # Standardisation des noms de colonnes
    df.columns = df.columns.str.replace("[‚Äô'‚Äò]", "'", regex=True)
    df.columns = df.columns.str.strip()
    
    # Print final columns for verification
    print("Final columns:", df.columns.tolist())
    
    return df

df = load_data()

# Verify columns in the app
st.write("Columns in DataFrame:", df.columns.tolist())

# --- Cat√©gories pour les filtres ---
age_categories = ["Moins de 18 ans", "18-25 ans", "26-40 ans", "41-60 ans", "Plus de 60 ans"]
gender_categories = ["Homme", "Femme", "Autre / Pr√©f√®re ne pas r√©pondre"]
edu_categories = ["Coll√®ge ou moins", "Lyc√©e", "Bac +2", "Bac +3 / Licence", "Bac +5 et plus"]
platform_categories = ["Facebook", "Twitter", "Instagram", "TikTok", "YouTube", "LinkedIn", "Pas de r√©seau"]

# --- Barre lat√©rale avec filtres ---
with st.sidebar:
    st.title("üîç Filtres")
    
    with st.expander("D√©mographie", expanded=True):
        selected_ages = st.multiselect("Tranche d'√¢ge", age_categories, default=age_categories)
        selected_genders = st.multiselect("Genre", gender_categories, default=gender_categories)
        selected_edu = st.multiselect("Niveau d'√©ducation", edu_categories, default=edu_categories)
    
    with st.expander("Plateformes", expanded=False):
        selected_platforms = st.multiselect("R√©seaux sociaux principaux", platform_categories, default=platform_categories)
    
    with st.expander("Options avanc√©es", expanded=False):
        show_raw_data = st.checkbox("Afficher les donn√©es brutes")
        cluster_analysis = st.checkbox("Activer l'analyse par clusters")
        if cluster_analysis:
            n_clusters = st.slider("Nombre de clusters", 2, 5, 3)
    
    st.markdown("""
    <div style="text-align: center; font-size: 0.8em; color: #666;">
        Dashboard cr√©√© avec Streamlit<br>
        Donn√©es DeepFakes - 2025
    </div>
    """, unsafe_allow_html=True)

# --- Application des filtres ---
df_filtered = df.copy()

if selected_ages and len(selected_ages) != len(age_categories):
    df_filtered = df_filtered[df_filtered["Age"].isin(selected_ages)]
if selected_genders and len(selected_genders) != len(gender_categories):
    df_filtered = df_filtered[df_filtered["Genre"].isin(selected_genders)]
if selected_edu and len(selected_edu) != len(edu_categories):
    df_filtered = df_filtered[df_filtered["Education"].isin(selected_edu)]
if selected_platforms and len(selected_platforms) != len(platform_categories):
    df_filtered = df_filtered[df_filtered["Reseau_Social"].isin(selected_platforms)]

total_respondents = len(df_filtered)

# --- Fonctions utilitaires ---
def get_percentage_distribution(column_name, categories_order=None, multi_choice=False):
    if total_respondents == 0:
        return pd.Series(dtype=float)
    
    if multi_choice:
        answers_series = df_filtered[column_name].dropna().str.split(';').explode().str.strip()
        counts = answers_series.value_counts()
    else:
        counts = df_filtered[column_name].dropna().value_counts()
    
    perc = (counts * 100 / total_respondents).round(1)
    
    if categories_order:
        for cat in categories_order:
            if cat not in perc.index:
                perc.loc[cat] = 0.0
        perc = perc[categories_order]
    
    return perc

def create_sunburst_chart(df, path, values, color, title):
    fig = px.sunburst(
        df,
        path=path,
        values=values,
        color=color,
        title=title,
        height=600
    )
    fig.update_layout(margin=dict(t=50, l=0, r=0, b=0))
    return fig

def create_radar_chart(categories, values, title):
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        name=title
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, max(values)*1.1 if len(values) > 0 else 100]
            )),
        showlegend=False,
        title=title,
        height=400,
        margin=dict(l=50, r=50, t=50, b=50)
    )
    
    return fig

# --- Navigation par onglets ---
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìä Tableau de bord", 
    "üîç Analyse approfondie", 
    "üì± Plateformes", 
    "üõ°Ô∏è Impact & Protection", 
    "ü§ñ Analyse avanc√©e"
])

with tab1:
    st.title("üìä Tableau de bord DeepFakes")
    
    # KPI Cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        awareness = get_percentage_distribution(COL_AWARENESS, ["Oui"]).get("Oui", 0)
        st.metric("Conscience des DeepFakes", f"{awareness}%", "92% globale")
    
    with col2:
        exposure = get_percentage_distribution(COL_EXPOSURE, ["Oui"]).get("Oui", 0)
        st.metric("Exposition aux DeepFakes", f"{exposure}%", "78% globale")
    
    with col3:
        neg_impact = get_percentage_distribution(COL_IMPACT, ["Tr√®s n√©gatif", "N√©gatif"])
        total_neg_impact = neg_impact.get("Tr√®s n√©gatif", 0) + neg_impact.get("N√©gatif", 0)
        st.metric("Impact n√©gatif", f"{total_neg_impact}%", "65% globale")

    with col4:
        verification = get_percentage_distribution(COL_VERIFICATION, ["Souvent", "Toujours"])
        total_verify = verification.get("Souvent", 0) + verification.get("Toujours", 0)
        st.metric("V√©rification active", f"{total_verify}%", "72% globale")
    
    style_metric_cards(border_left_color="#DBF227", box_shadow=True)
    
    # Visualisations principales
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Connaissance des DeepFakes")
        knowledge = get_percentage_distribution(
            COL_KNOWLEDGE,
            ["Pas du tout inform√©(e)", "Peu inform√©(e)", "Moyennement inform√©(e)", "Bien inform√©(e)", "Tr√®s bien inform√©(e)"]
        )
        
        if not knowledge.empty:
            knowledge_df = pd.DataFrame({
                'Niveau': knowledge.index,
                'Pourcentage': knowledge.values
            })
            
            fig = px.bar(
                knowledge_df,
                x='Niveau',
                y='Pourcentage',
                labels={'Niveau': 'Niveau de connaissance', 'Pourcentage': 'Pourcentage (%)'},
                color='Niveau',
                color_discrete_sequence=px.colors.sequential.Blues_r
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
    with col2:
        st.subheader("Impact per√ßu par domaine")
        domains = get_percentage_distribution(
            "Quels domaines vous semblent les plus touch√©s par les deep fakes ? (Plusieurs choix possibles)",
            ["Politique", "Divertissement/C√©l√©brit√©s", "Journalisme/Actualit√©s", "Informations financi√®res", "√âv√©nements sociaux (crises, catastrophes, etc.)"],
            multi_choice=True
        )
        
        if not domains.empty:
            domains_df = pd.DataFrame({
                'Domaine': domains.index,
                'Pourcentage': domains.values
            })
            
            fig = create_radar_chart(
                domains_df['Domaine'],
                domains_df['Pourcentage'],
                "Domaines les plus impact√©s"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
    # Heatmap des plateformes
    st.subheader("Pr√©sence des DeepFakes par plateforme")
    platforms_data = get_percentage_distribution(
        COL_PLATFORMS,
        ["Facebook", "Twitter", "Instagram", "TikTok", "YouTube", "Autres"],
        multi_choice=True
    )
    
    if not platforms_data.empty:
        platforms_df = pd.DataFrame({
            'Plateforme': platforms_data.index,
            'Pourcentage': platforms_data.values
        })
        
        fig = px.bar(
            platforms_df,
            x='Plateforme',
            y='Pourcentage',
            labels={'Pourcentage': 'Pourcentage (%)'},
            color='Pourcentage',
            color_continuous_scale='Blues'
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Aucune donn√©e disponible pour ce filtre")

# [Le code pr√©c√©dent jusqu'√† la section des onglets reste identique...]

with tab2:
    st.title("üîç Analyse approfondie")
    
    tab2_col1, tab2_col2 = st.columns([1, 2])
    
    with tab2_col1:
        st.subheader("R√©partition d√©mographique")
        
        # Sunburst chart
        df_demo = df_filtered.groupby(['Age', 'Genre', 'Education']).size().reset_index(name='counts')
        if not df_demo.empty:
            fig = px.sunburst(
                df_demo,
                path=['Age', 'Genre', 'Education'],
                values='counts',
                color='counts',
                title="R√©partition par √Çge, Genre et √âducation",
                height=600
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
with tab2_col1:
    st.subheader("R√©partition d√©mographique")
    
    try:
        # Sunburst chart
        df_demo = df_filtered.groupby(['Age', 'Genre', 'Education']).size().reset_index(name='counts')
        if not df_demo.empty:
            fig = px.sunburst(
                df_demo,
                path=['Age', 'Genre', 'Education'],
                values='counts',
                color='counts',
                title="R√©partition par √Çge, Genre et √âducation",
                height=600
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    except KeyError as e:
        st.error(f"Erreur de colonne: {str(e)}")
        st.write("Colonnes disponibles:", df_filtered.columns.tolist())
    
    # Analyse des m√©thodes de v√©rification
    st.subheader("M√©thodes de v√©rification par groupe")
    
    verification_methods = [
        "Rechercher d'autres sources fiables",
        "V√©rifier l'auteur et la cr√©dibilit√© du m√©dia",
        "Utiliser des outils de fact-checking (ex : D√©codex, Snopes)",
        "Analyser les commentaires et r√©actions d'autres utilisateurs",
        "Je ne v√©rifie pas"
    ]
    
    group_by = st.selectbox(
        "Grouper par",
        ["Age", "Genre", "Education", "Reseau_Social"],
        index=1
    )
    
    if not df_filtered.empty:
        method_data = []
        for method in verification_methods:
            temp_df = df_filtered[df_filtered[COL_METHODS].str.contains(method, na=False)]
            counts = temp_df.groupby(group_by).size() / df_filtered.groupby(group_by).size() * 100
            method_data.append(counts)
        
        method_df = pd.concat(method_data, axis=1)
        method_df.columns = verification_methods
        method_df = method_df.fillna(0)
        
        fig = px.bar(
            method_df.reset_index(),
            x=group_by,
            y=verification_methods,
            barmode='group',
            labels={'value': 'Pourcentage', 'variable': 'M√©thode'},
            color_discrete_sequence=px.colors.qualitative.Pastel,
            title="M√©thodes de v√©rification par groupe"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Aucune donn√©e disponible pour ce filtre")

with tab3:
    st.title("üì± Analyse par Plateforme")
    
    platform_tab1, platform_tab2, platform_tab3 = st.tabs(["Exposition", "Confiance", "Comportements"])
    
    with platform_tab1:
        st.subheader("Exposition aux DeepFakes par plateforme")
        
        platform_exposure = get_percentage_distribution(
            COL_PLATFORMS,
            ["Facebook", "Twitter", "Instagram", "TikTok", "YouTube", "Autres"],
            multi_choice=True
        )
        
        if not platform_exposure.empty:
            fig = px.bar(
                platform_exposure.reset_index().rename(columns={'index': 'Plateforme', 0: 'Pourcentage'}),
                x='Plateforme',
                y='Pourcentage',
                labels={'Pourcentage': 'Pourcentage (%)'},
                color='Plateforme',
                color_discrete_sequence=px.colors.sequential.Magenta,
                title="Plateformes o√π les DeepFakes sont le plus vus"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
        
        st.subheader("Exposition vs R√©seau social principal")
        
        if not df_filtered.empty:
            exposure_vs_main = pd.crosstab(
                df_filtered["Reseau_Social"],
                df_filtered[COL_EXPOSURE],
                normalize='index'
            ).round(2) * 100
            
            fig = px.bar(
                exposure_vs_main.reset_index(),
                x="Reseau_Social",
                y=["Oui", "Non", "Je ne suis pas s√ªr(e)"],
                barmode='group',
                labels={'value': 'Pourcentage', 'variable': 'R√©ponse'},
                color_discrete_sequence=px.colors.qualitative.Set2,
                title="Exposition aux DeepFakes par r√©seau principal"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
    with platform_tab2:
        st.subheader("Confiance par plateforme principale")
        
        if not df_filtered.empty:
            trust_by_platform = pd.crosstab(
                df_filtered["Reseau_Social"],
                df_filtered[COL_TRUST],
                normalize='index'
            ).round(2) * 100
            
            fig = px.bar(
                trust_by_platform.reset_index(),
                x="Reseau_Social",
                y=["Oui", "Non", "Cela d√©pend des sources"],
                barmode='group',
                labels={'value': 'Pourcentage', 'variable': 'Niveau de confiance'},
                color_discrete_sequence=px.colors.sequential.Plasma,
                title="Confiance dans les informations par plateforme"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
        
        st.subheader("√âvolution de la confiance")
        
        if not df_filtered.empty:
            trust_evolution = pd.crosstab(
                df_filtered["Reseau_Social"],
                df_filtered[COL_TRUST_CHANGE],
                normalize='index'
            ).round(2) * 100
            
            fig = px.bar(
                trust_evolution.reset_index(),
                x="Reseau_Social",
                y=["Fortement diminu√©", "L√©g√®rement diminu√©", "Rest√© stable", "L√©g√®rement augment√©", "Fortement augment√©"],
                barmode='group',
                labels={'value': 'Pourcentage', 'variable': '√âvolution'},
                color_discrete_sequence=px.colors.sequential.Plasma_r,
                title="√âvolution de la confiance apr√®s connaissance des DeepFakes"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
    with platform_tab3:
        st.subheader("Comportements par plateforme")
        
        st.write("**R√©duction du partage d'informations**")
        if not df_filtered.empty:
            sharing_reduction = pd.crosstab(
                df_filtered["Reseau_Social"],
                df_filtered[COL_SHARING],
                normalize='index'
            ).round(2) * 100
            
            fig = px.bar(
                sharing_reduction.reset_index(),
                x="Reseau_Social",
                y=["Pas du tout", "L√©g√®rement", "Moyennement", "Beaucoup", "Tr√®s fortement"],
                barmode='group',
                labels={'value': 'Pourcentage', 'variable': 'Niveau de r√©duction'},
                color_discrete_sequence=px.colors.sequential.Viridis,
                title="R√©duction du partage d'informations par plateforme"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
        
        st.write("**Fr√©quence de v√©rification**")
        if not df_filtered.empty:
            verification_freq = pd.crosstab(
                df_filtered["Reseau_Social"],
                df_filtered[COL_VERIFICATION],
                normalize='index'
            ).round(2) * 100
            
            fig = px.bar(
                verification_freq.reset_index(),
                x="Reseau_Social",
                y=["Jamais", "Rarement", "Parfois", "Souvent", "Toujours"],
                barmode='group',
                labels={'value': 'Pourcentage', 'variable': 'Fr√©quence'},
                color_discrete_sequence=px.colors.sequential.Viridis_r,
                title="Fr√©quence de v√©rification par plateforme"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")

with tab4:
    st.title("üõ°Ô∏è Impact & Protection")
    
    impact_tab1, impact_tab2 = st.tabs(["Impact per√ßu", "Strat√©gies de protection"])
    
    with impact_tab1:
        st.subheader("Impact global sur la soci√©t√©")
        
        impact_dist = get_percentage_distribution(
            COL_IMPACT,
            ["Tr√®s n√©gatif", "N√©gatif", "Neutre", "Positif", "Tr√®s positif"]
        )
        
        if not impact_dist.empty:
            fig = px.pie(
                impact_dist.reset_index().rename(columns={'index': 'Impact', 0: 'Pourcentage'}),
                values='Pourcentage',
                names='Impact',
                hole=0.4,
                color_discrete_sequence=px.colors.sequential.RdBu,
                title="Perception de l'impact global des DeepFakes"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
        
        st.subheader("Domaines les plus impact√©s")
        
        domains_impact = get_percentage_distribution(
            "Quels domaines vous semblent les plus touch√©s par les deep fakes ? (Plusieurs choix possibles)",
            ["Politique", "Divertissement/C√©l√©brit√©s", "Journalisme/Actualit√©s", "Informations financi√®res", "√âv√©nements sociaux (crises, catastrophes, etc.)"],
            multi_choice=True
        )
        
        if not domains_impact.empty:
            fig = px.bar(
                domains_impact.reset_index().rename(columns={'index': 'Domaine', 0: 'Pourcentage'}),
                x='Pourcentage',
                y='Domaine',
                orientation='h',
                color='Domaine',
                color_discrete_sequence=px.colors.sequential.RdBu_r,
                title="Domaines per√ßus comme les plus impact√©s"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
    
    with impact_tab2:
        st.subheader("M√©thodes de v√©rification")
        
        verification_methods = get_percentage_distribution(
            COL_METHODS,
            [
                "Rechercher d'autres sources fiables",
                "V√©rifier l'auteur et la cr√©dibilit√© du m√©dia",
                "Utiliser des outils de fact-checking (ex : D√©codex, Snopes)",
                "Analyser les commentaires et r√©actions d'autres utilisateurs",
                "Je ne v√©rifie pas"
            ],
            multi_choice=True
        )
        
        if not verification_methods.empty:
            fig = px.bar(
                verification_methods.reset_index().rename(columns={'index': 'M√©thode', 0: 'Pourcentage'}),
                x='Pourcentage',
                y='M√©thode',
                orientation='h',
                color='M√©thode',
                color_discrete_sequence=px.colors.qualitative.Set3,
                title="M√©thodes de v√©rification les plus utilis√©es"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")
        
        st.subheader("Outils de v√©rification par niveau de connaissance")
        
        if not df_filtered.empty:
            knowledge_levels = [
                "Pas du tout inform√©(e)",
                "Peu inform√©(e)",
                "Moyennement inform√©(e)",
                "Bien inform√©(e)",
                "Tr√®s bien inform√©(e)"
            ]
            
            tools_by_knowledge = []
            for method in verification_methods.index:
                temp_df = df_filtered[df_filtered[COL_METHODS].str.contains(method, na=False)]
                counts = temp_df.groupby(COL_KNOWLEDGE).size() / df_filtered.groupby(COL_KNOWLEDGE).size() * 100
                tools_by_knowledge.append(counts)
            
            tools_df = pd.concat(tools_by_knowledge, axis=1)
            tools_df.columns = verification_methods.index
            tools_df = tools_df.reindex(knowledge_levels)
            tools_df = tools_df.fillna(0)
            
            fig = px.line(
                tools_df.reset_index().rename(columns={'index': 'Niveau de connaissance'}),
                x="Niveau de connaissance",
                y=tools_df.columns,
                markers=True,
                labels={'value': 'Pourcentage', 'variable': 'M√©thode'},
                color_discrete_sequence=px.colors.qualitative.Set3,
                title="M√©thodes de v√©rification par niveau de connaissance"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucune donn√©e disponible pour ce filtre")

with tab5:
    st.title("ü§ñ Analyse avanc√©e")
    
    adv_tab1, adv_tab2, adv_tab3 = st.tabs(["Analyse par clusters", "Pr√©diction d'impact", "Donn√©es brutes"])
    
    with adv_tab1:
        if cluster_analysis:
            st.subheader("Segmentation des r√©pondants par clusters")
            
            # Pr√©paration des donn√©es pour le clustering
            cluster_features = pd.DataFrame()
            
            # Encodage des caract√©ristiques
            cluster_features['Age_encoded'] = df_filtered['Age'].map({
                "Moins de 18 ans": 0,
                "18-25 ans": 1,
                "26-40 ans": 2,
                "41-60 ans": 3,
                "Plus de 60 ans": 4
            })
            
            cluster_features['Education_encoded'] = df_filtered['Education'].map({
                "Coll√®ge ou moins": 0,
                "Lyc√©e": 1,
                "Bac +2": 2,
                "Bac +3 / Licence": 3,
                "Bac +5 et plus": 4
            })
            
            cluster_features['Exposure'] = df_filtered[COL_EXPOSURE].map({
                "Oui": 1,
                "Non": 0,
                "Je ne suis pas s√ªr(e)": 0.5
            })
            
            cluster_features['Trust'] = df_filtered[COL_TRUST].map({
                "Oui": 1,
                "Non": 0,
                "Cela d√©pend des sources": 0.5
            })
            
            if not cluster_features.empty:
                # Normalisation
                scaler = StandardScaler()
                features_scaled = scaler.fit_transform(cluster_features)
                
                # Clustering
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                clusters = kmeans.fit_predict(features_scaled)
                
                # Ajout des clusters aux donn√©es
                df_clustered = df_filtered.copy()
                df_clustered['Cluster'] = clusters
                
                # Visualisation des clusters
                st.write(f"**R√©partition des {n_clusters} clusters**")
                cluster_dist = df_clustered['Cluster'].value_counts(normalize=True) * 100
                fig = px.pie(
                    cluster_dist.reset_index().rename(columns={'index': 'Cluster', 'proportion': 'Pourcentage'}),
                    values='Pourcentage',
                    names='Cluster',
                    hole=0.3,
                    color_discrete_sequence=px.colors.sequential.Plasma,
                    title=f"R√©partition des {n_clusters} clusters"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Caract√©ristiques des clusters
                st.write("**Caract√©ristiques moyennes par cluster**")
                
                cluster_means = df_clustered.groupby('Cluster').agg({
                    'Age': lambda x: x.mode()[0],
                    'Education': lambda x: x.mode()[0],
                    'Reseau_Social': lambda x: x.mode()[0],
                    COL_EXPOSURE: lambda x: (x == 'Oui').mean() * 100,
                    COL_TRUST: lambda x: (x == 'Oui').mean() * 100,
                    COL_VERIFICATION: lambda x: (x.isin(['Souvent', 'Toujours'])).mean() * 100
                }).rename(columns={
                    COL_EXPOSURE: '% Exposition',
                    COL_TRUST: '% Confiance',
                    COL_VERIFICATION: '% V√©rification fr√©quente'
                })
                
                st.dataframe(
                    cluster_means.style.background_gradient(cmap='Blues'),
                    use_container_width=True
                )
                
                # Radar chart pour comparer les clusters
                st.write("**Comparaison des clusters**")
                
                radar_data = df_clustered.groupby('Cluster').agg({
                    'Age_encoded': 'mean',
                    'Education_encoded': 'mean',
                    'Exposure': 'mean',
                    'Trust': 'mean'
                }).reset_index()
                
                fig = go.Figure()
                
                for cluster in range(n_clusters):
                    fig.add_trace(go.Scatterpolar(
                        r=radar_data.loc[cluster, ['Age_encoded', 'Education_encoded', 'Exposure', 'Trust']].values,
                        theta=['Age', 'Education', 'Exposure', 'Trust'],
                        fill='toself',
                        name=f'Cluster {cluster}'
                    ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, 1]
                        )),
                    showlegend=True,
                    height=500,
                    title="Comparaison des clusters par caract√©ristiques"
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Aucune donn√©e disponible pour le clustering")
        else:
            st.warning("Activez l'analyse par clusters dans les options avanc√©es de la barre lat√©rale")
    
    with adv_tab2:
        st.subheader("Pr√©diction de l'impact per√ßu")
        
        st.write("""
        Ce mod√®le pr√©dit la probabilit√© qu'une personne per√ßoive un impact n√©gatif des DeepFakes en fonction de ses caract√©ristiques.
        """)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            age_pred = st.selectbox("√Çge", age_categories, index=2)
        
        with col2:
            gender_pred = st.selectbox("Genre", gender_categories, index=0)
        
        with col3:
            edu_pred = st.selectbox("Niveau d'√©ducation", edu_categories, index=4)
        
        platform_pred = st.selectbox("R√©seau social principal", platform_categories, index=2)
        
        if st.button("Pr√©dire l'impact"):
            # Simulation simple d'un mod√®le de pr√©diction
            impact_prob = 0.5  # baseline
            
            # Ajustements bas√©s sur l'√¢ge
            if age_pred == "18-25 ans":
                impact_prob += 0.15
            elif age_pred == "26-40 ans":
                impact_prob += 0.10
            elif age_pred == "41-60 ans":
                impact_prob += 0.05
            
            # Ajustements bas√©s sur l'√©ducation
            if edu_pred == "Bac +5 et plus":
                impact_prob += 0.20
            elif edu_pred == "Bac +3 / Licence":
                impact_prob += 0.15
            
            # Ajustements bas√©s sur la plateforme
            if platform_pred == "Twitter":
                impact_prob += 0.10
            elif platform_pred == "Facebook":
                impact_prob += 0.05
            
            # Normalisation entre 0 et 1
            impact_prob = max(0, min(1, impact_prob))
            
            # Visualisation
            fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = impact_prob*100,
                number = {'suffix': "%"},
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Probabilit√© d'impact n√©gatif per√ßu"},
                gauge = {
                    'axis': {'range': [0, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgreen"},
                        {'range': [50, 75], 'color': "yellow"},
                        {'range': [75, 100], 'color': "red"}]
                }
            ))
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Explication
            with st.expander("Explication des facteurs influen√ßant la pr√©diction"):
                st.write("""
                - **√Çge**: Les jeunes adultes (18-25 ans) sont plus susceptibles de percevoir un impact n√©gatif
                - **√âducation**: Les personnes avec un niveau d'√©ducation sup√©rieur sont plus conscientes des risques
                - **Plateforme**: Les utilisateurs de Twitter et Facebook sont plus expos√©s aux DeepFakes
                """)
    
    with adv_tab3:
        if show_raw_data:
            st.subheader("Donn√©es brutes filtr√©es")
            st.dataframe(df_filtered, use_container_width=True)
            
            # Options d'export
            csv = df_filtered.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="T√©l√©charger les donn√©es filtr√©es (CSV)",
                data=csv,
                file_name='deepfakes_data_filtered.csv',
                mime='text/csv'
            )
        else:
            st.info("Activez l'option 'Afficher les donn√©es brutes' dans les options avanc√©es de la barre lat√©rale")


# --- Pied de page ---
st.markdown("""
<hr style="border:0.5px solid #ddd; margin-top: 30px; margin-bottom: 20px;">
<div style="text-align: center; color: #666; font-size: 0.9em;">
    Dashboard DeepFakes - ¬© 2025 | Cr√©√© avec Streamlit | Donn√©es anonymis√©es
</div>
""", unsafe_allow_html=True)